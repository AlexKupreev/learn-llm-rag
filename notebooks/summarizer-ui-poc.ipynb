{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Summarizer - User Interface - Proof of Concept",
   "id": "895b241e7f0998c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ],
   "id": "16dcc1db420a3448"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T12:08:43.325992Z",
     "start_time": "2024-10-29T12:08:43.321290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from datetime import date, datetime\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from llm import NoRelevantDataFoundError, extract_from_llm_output, openai_llm, rag\n",
    "from vectordb import MilvusClientFix, milvus_search\n"
   ],
   "id": "1d6474396de14e43",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T10:56:39.592373Z",
     "start_time": "2024-10-29T10:56:39.588237Z"
    }
   },
   "cell_type": "code",
   "source": "nb_path = Path()",
   "id": "f7fd4493ffaed5db",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T10:56:39.752533Z",
     "start_time": "2024-10-29T10:56:39.678511Z"
    }
   },
   "cell_type": "code",
   "source": "load_dotenv(nb_path / \"../.env\", verbose=True)",
   "id": "584c52a3f245c4d6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configuration and initialization",
   "id": "1bf69fa453c71aa2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T11:54:16.856526Z",
     "start_time": "2024-10-29T11:54:16.851670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hn_dump_file = \"hn_news.json\"\n",
    "lr_dump_file = \"lr_news.json\"\n",
    "\n",
    "collection_name = \"llm_summarizer_poc\"\n",
    "collection_db_path = \"./milvus_summarizer.db\""
   ],
   "id": "f2c59b19c8e5f68e",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T10:56:40.960112Z",
     "start_time": "2024-10-29T10:56:39.875571Z"
    }
   },
   "cell_type": "code",
   "source": "milvus_client = MilvusClientFix.get_instance(collection_db_path)",
   "id": "68893a5eac2c9b4e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T10:56:41.010758Z",
     "start_time": "2024-10-29T10:56:40.968722Z"
    }
   },
   "cell_type": "code",
   "source": "openai_client = OpenAI()",
   "id": "2d3c99462a4c18d4",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T10:56:41.227444Z",
     "start_time": "2024-10-29T10:56:41.023376Z"
    }
   },
   "cell_type": "code",
   "source": "milvus_search_fn = partial(milvus_search, milvus_client, collection_name)",
   "id": "137245b8d31618af",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T10:56:41.425775Z",
     "start_time": "2024-10-29T10:56:41.265405Z"
    }
   },
   "cell_type": "code",
   "source": "openai_llm_fn = partial(openai_llm, openai_client)",
   "id": "59ac0a387a23d430",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T10:56:41.555924Z",
     "start_time": "2024-10-29T10:56:41.467501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_summary_prompt(query: str, search_results: list[dict]) -> str:\n",
    "    prompt_template = \"\"\"\n",
    "You're the skilled specialist. Summarize the most important points from the CONTEXT that might be useful or interesting for a specialist and related to  QUERY. \n",
    "Use only the facts from the CONTEXT when finding relevancy but provide some comparative summary with the state-of-the-arts if possible.\n",
    "If the context fragment does not have close relation to the query, provide a short note why a fragment is not relevant.\n",
    "Provide the output as JSON with the list of dictionaries with the following fields: fragment_id, summary, is_relevant. Value in is_relevant should be True if the fragment is relevant to the KEYWORDS and False otherwise.\n",
    "\n",
    "QUERY: {query}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for idx, doc in enumerate(search_results):\n",
    "        context = context + f\"FRAGMENT_{doc['document_uid']}: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(query=query, context=context).strip()\n",
    "    return prompt\n"
   ],
   "id": "8505b0392bec7458",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T10:56:41.670245Z",
     "start_time": "2024-10-29T10:56:41.569720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"Data Engineering\"\n",
    "start_date = None\n",
    "end_date = None"
   ],
   "id": "35cddf00073d34e9",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T10:56:56.380428Z",
     "start_time": "2024-10-29T10:56:41.683300Z"
    }
   },
   "cell_type": "code",
   "source": "rag_summary = rag(query, build_summary_prompt, openai_llm_fn, milvus_search_fn, start_dt=start_date, end_dt=end_date)",
   "id": "36ebe131b5e2e04c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T10:56:56.411Z",
     "start_time": "2024-10-29T10:56:56.405318Z"
    }
   },
   "cell_type": "code",
   "source": "rag_summary",
   "id": "d4e65381fb8e9a78",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n[\\n    {\\n        \"fragment_id\": \"FRAGMENT_47fa612996\",\\n        \"summary\": \"The trend of automated reasoning in software development, particularly at AWS, shows that formally verified code often outperforms unverified counterparts. Automated reasoning enhances system performance by verifying code correctness under various scenarios, thereby boosting developer confidence in optimization. This approach addresses the complexities and potential bugs in large-scale systems, replacing traditional testing methods with logical proofs of correctness. By moving towards a mathematical view of system specifications, it allows for handling complex, high-scale environments effectively.\",\\n        \"is_relevant\": true\\n    },\\n    {\\n        \"fragment_id\": \"FRAGMENT_37278e50d8\",\\n        \"summary\": \"This fragment discusses a fork of OpenTofu that uses CUE as a substitute for HCL in tools like Terraform and Helmfiles. While CUE may relate to data configuration, it lacks a direct connection to the core aspects of data engineering such as data integration, processing, or pipeline management.\",\\n        \"is_relevant\": false\\n    },\\n    {\\n        \"fragment_id\": \"FRAGMENT_f595a4c807\",\\n        \"summary\": \"The fragment examines TLA+ as a tool for modeling concurrent algorithms and database systems. Though it emphasizes the modeling and verification of concurrency, it is less focused on data engineering specifically and more on algorithm correctness, which may only tangentially impact data system operations.\",\\n        \"is_relevant\": false\\n    },\\n    {\\n        \"fragment_id\": \"FRAGMENT_3b3bf513d5\",\\n        \"summary\": \"This fragment describes a course on Game AI, focusing on classical AI techniques relevant in video game development. It does not pertain to data engineering, as its primary focus is on game programming rather than data processing, integration, or infrastructure.\",\\n        \"is_relevant\": false\\n    },\\n    {\\n        \"fragment_id\": \"FRAGMENT_84f8067aa1\",\\n        \"summary\": \"The rise in AI has increased the need for energy-efficient data centers, leading to interest in microreactors for sustainable power solutions. This fragment discusses the innovative power supply methods for data centers but does not directly address data engineering practices such as data processing or management.\",\\n        \"is_relevant\": false\\n    },\\n    {\\n        \"fragment_id\": \"FRAGMENT_b8bd768829\",\\n        \"summary\": \"Privacy4Cars focuses on the automotive industry’s methods for deleting personal data from vehicles, aimed at reducing liability and meeting regulatory requirements. The information is not relevant to data engineering, which typically deals with data processing, storage, and architecture.\",\\n        \"is_relevant\": false\\n    },\\n    {\\n        \"fragment_id\": \"FRAGMENT_0ddfee1b01\",\\n        \"summary\": \"This fragment describes the Supergraph architecture framework for API integration and data access among disparate systems. It emphasizes the need for efficient data flow and integration, aligning with data engineering goals of creating seamless data pipelines and interactions across systems. Its focus on self-serve platforms, API management, and composability directly relates to modern data engineering practices.\",\\n        \"is_relevant\": true\\n    }\\n]\\n```'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For every relevant fragment find most related documents from the whole history and provide a perspective on the topic.\n",
   "id": "27f4ca2873ba86a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T10:57:01.707113Z",
     "start_time": "2024-10-29T10:57:01.697452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rag_cleaned = extract_from_llm_output(rag_summary)\n",
    "rag_cleaned"
   ],
   "id": "5bed4fd3b33003e0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'fragment_id': 'FRAGMENT_47fa612996',\n",
       "  'summary': 'The trend of automated reasoning in software development, particularly at AWS, shows that formally verified code often outperforms unverified counterparts. Automated reasoning enhances system performance by verifying code correctness under various scenarios, thereby boosting developer confidence in optimization. This approach addresses the complexities and potential bugs in large-scale systems, replacing traditional testing methods with logical proofs of correctness. By moving towards a mathematical view of system specifications, it allows for handling complex, high-scale environments effectively.',\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': 'FRAGMENT_37278e50d8',\n",
       "  'summary': 'This fragment discusses a fork of OpenTofu that uses CUE as a substitute for HCL in tools like Terraform and Helmfiles. While CUE may relate to data configuration, it lacks a direct connection to the core aspects of data engineering such as data integration, processing, or pipeline management.',\n",
       "  'is_relevant': False},\n",
       " {'fragment_id': 'FRAGMENT_f595a4c807',\n",
       "  'summary': 'The fragment examines TLA+ as a tool for modeling concurrent algorithms and database systems. Though it emphasizes the modeling and verification of concurrency, it is less focused on data engineering specifically and more on algorithm correctness, which may only tangentially impact data system operations.',\n",
       "  'is_relevant': False},\n",
       " {'fragment_id': 'FRAGMENT_3b3bf513d5',\n",
       "  'summary': 'This fragment describes a course on Game AI, focusing on classical AI techniques relevant in video game development. It does not pertain to data engineering, as its primary focus is on game programming rather than data processing, integration, or infrastructure.',\n",
       "  'is_relevant': False},\n",
       " {'fragment_id': 'FRAGMENT_84f8067aa1',\n",
       "  'summary': 'The rise in AI has increased the need for energy-efficient data centers, leading to interest in microreactors for sustainable power solutions. This fragment discusses the innovative power supply methods for data centers but does not directly address data engineering practices such as data processing or management.',\n",
       "  'is_relevant': False},\n",
       " {'fragment_id': 'FRAGMENT_b8bd768829',\n",
       "  'summary': 'Privacy4Cars focuses on the automotive industry’s methods for deleting personal data from vehicles, aimed at reducing liability and meeting regulatory requirements. The information is not relevant to data engineering, which typically deals with data processing, storage, and architecture.',\n",
       "  'is_relevant': False},\n",
       " {'fragment_id': 'FRAGMENT_0ddfee1b01',\n",
       "  'summary': 'This fragment describes the Supergraph architecture framework for API integration and data access among disparate systems. It emphasizes the need for efficient data flow and integration, aligning with data engineering goals of creating seamless data pipelines and interactions across systems. Its focus on self-serve platforms, API management, and composability directly relates to modern data engineering practices.',\n",
       "  'is_relevant': True}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T12:07:53.796422Z",
     "start_time": "2024-10-29T12:07:53.786999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from more_itertools import chunked\n",
    "\n",
    "MAX_SCOPE = 100\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "def rag_batched(\n",
    "    query: str,\n",
    "    prompt_fn: callable,\n",
    "    llm_fn: callable,\n",
    "    search_fn: callable,\n",
    "    num_results: int = MAX_SCOPE,\n",
    "    batch_size: int = BATCH_SIZE,\n",
    "    start_dt: datetime | None = None,\n",
    "    end_dt: datetime | None = None\n",
    ") -> list[dict]:\n",
    "    \"\"\"Return relevant answers built using RAG.\n",
    "    \n",
    "    The goal is to find relevant documents and disregard irrelevant ones.\n",
    "    Take a lot of documents, split them into batches. Assume that documents are ordered by \"distance\" between embeddings. If two consecutive batches do not contain relevant fragments, stop the process.\n",
    "    \n",
    "    LLM Response should contain a list of dictionaries with at least \"is_relevant\" field. \n",
    "    \"\"\"\n",
    "    search_results = search_fn(\n",
    "        query=query,\n",
    "        num_results=num_results,\n",
    "        start_dt=start_dt,\n",
    "        end_dt=end_dt\n",
    "    )\n",
    "    \n",
    "    if not search_results:\n",
    "        raise NoRelevantDataFoundError(\"No relevant results found.\")\n",
    "    \n",
    "    prev_batch_relevant = True\n",
    "    relevant_results = []\n",
    "    for batch in tqdm(chunked(search_results, batch_size)):\n",
    "        prompt = prompt_fn(query, batch)\n",
    "        answer = llm_fn(prompt)\n",
    "        \n",
    "        cleaned = extract_from_llm_output(answer)\n",
    "        count_relevant = 0\n",
    "        for item in cleaned:\n",
    "            if item[\"is_relevant\"]:\n",
    "                relevant_results.append(item)\n",
    "                count_relevant += 1\n",
    "                \n",
    "        if count_relevant == 0:\n",
    "            if not prev_batch_relevant:\n",
    "                break\n",
    "            \n",
    "            prev_batch_relevant = False\n",
    "\n",
    "    return relevant_results"
   ],
   "id": "464cdcca4411ce85",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T11:59:03.134310Z",
     "start_time": "2024-10-29T11:56:33.435309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "extended_summary = rag_batched(query, build_summary_prompt, openai_llm_fn, milvus_search_fn, start_dt=start_date, end_dt=end_date)\n",
    "\n",
    "extended_summary"
   ],
   "id": "d1413742fd468743",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b7ea1a0944dc4c298b8de214432313a9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'fragment_id': '47fa612996',\n",
       "  'summary': \"Automated reasoning has improved the performance and maintainability of AWS's complex distributed systems, allowing for more efficient bug fixes and optimizations beyond traditional testing methods. This approach is especially useful for large-scale, fault-tolerant architectures, enhancing system correctness and developer confidence.\",\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': '0ddfee1b01',\n",
       "  'summary': 'The Supergraph Manifesto outlines an architecture framework for API integration and federated data access, emphasizing self-service platforms for data access. It relates to data engineering in the context of building accessible data architectures and efficient data sharing practices.',\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': 'ad243e2f3b',\n",
       "  'summary': \"The data breach at the Internet Archive highlights significant issues in data security practices, revealing vulnerabilities in log management and user credential protection. The incident, which compromised over 31 million users' personal information, underlines the necessity of secure data engineering practices, especially for organizations handling large amounts of sensitive data. This incident serves as a reminder for data engineers to prioritize security protocols and password management to prevent unauthorized access.\",\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': '8ecce048c8',\n",
       "  'summary': 'The history of Unix and the evolution of interoperability standards such as POSIX highlights foundational knowledge about system-level data management. Understanding these historical contexts and system specifications is useful for data engineers in maintaining and designing systems that process and manipulate data efficiently. This relevance is rooted in the significance of standards in stable data engineering practices.',\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': 'adb3888124',\n",
       "  'summary': 'CloudTail is an open-source tool designed to enhance log management across multi-cloud environments, making it very pertinent to data engineering. Its features, including configurable event filtering and retention management, are crucial for data engineers tasked with maintaining compliance and security in logging practices within cloud infrastructures.',\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': 'FRAGMENT_4a574dbea6',\n",
       "  'summary': \"The launch of the first verified GPS/GNSS Data Stream service in Europe by NSAI NML emphasizes the importance of reliable and accurate GNSS data for Ireland's digital economy, enhancing public safety and enabling efficient navigation. This initiative aims to mitigate risks associated with GNSS data manipulation, such as spoofing, thereby improving the resilience of critical infrastructure. Specialists in data engineering may find this development significant as it highlights the intersection of data integrity and infrastructure reliability, relevant for applications in logistics, emergency response, and navigation systems.\",\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': 'FRAGMENT_d5f95a3c85',\n",
       "  'summary': \"This paper discusses the complexities of neural network training, emphasizing the emergent properties that arise from statistical mechanisms. While the primary focus isn't directly on data engineering, understanding neural networks' features and their holistic training could inform approaches to processing and analyzing data, particularly in machine learning contexts. The findings could enhance data engineering strategies by offering insights into model interpretability and computational efficiency, which are crucial in large-scale data applications.\",\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': 'FRAGMENT_59409c2ca9',\n",
       "  'summary': 'The article critiques the PHP-driven trend in domain-driven design (DDD), suggesting that an overemphasis on tactical coding patterns detracts from achieving genuine understanding and value in software development. For data engineers, this perspective on the strategic importance of understanding business domains over merely implementing patterns can inform better architectural decisions in data systems, ensuring alignment with overarching business goals and data utility.',\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': 'FRAGMENT_b4e95ed124',\n",
       "  'summary': 'This piece details the pitfalls of excessive use of abstractions in software design, emphasizing the importance of balancing abstraction with performance and complexity. For data engineers, this message is pertinent as it underscores the necessity of maintaining efficiency when handling data systems, ensuring that abstractions do not impede the operational performance of data processing workflows.',\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': 'FRAGMENT_fae9e36c2c',\n",
       "  'summary': 'This fragment provides an overview of transaction management in databases, emphasizing the significance of ACID properties for reliable data systems. For data engineers, understanding transaction isolation levels and their implications on data integrity is essential for designing robust data architectures, particularly in applications requiring concurrent data access and manipulation.',\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': 'FRAGMENT_fa746b5bb3',\n",
       "  'summary': 'This discussion revolves around a new platform created to capture and organize employee feedback within organizations. While the solution focuses on idea management, it relates to data engineering by touching on data collection and structuring for actionable insights. It highlights the importance of system design in data usability, which is relevant when engineering data solutions aimed at improving organizational decision-making.',\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': 'FRAGMENT_e305a722f3',\n",
       "  'summary': \"Cloudflare's use of OpenBMC for managing server fleets demonstrates the importance of effective infrastructure management in data engineering. The BMC monitors various subsystems during server boot, highlighting the need for reliable data handling in large-scale operations. The article also emphasizes the significance of open-source solutions for flexibility and rapid feature development, which aligns with trends towards transparency and community contributions in data engineering.\",\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': 'FRAGMENT_6cc3cd63eb',\n",
       "  'summary': \"Highlights a tool named 'zizmor' designed to identify security issues in GitHub Actions, aligning with the increasing focus on security in CI/CD pipelines. This is particularly relevant for data engineers dealing with data workflows within GitHub, as they need to maintain data integrity and security in automated processes.\",\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': 'FRAGMENT_136743ff0c',\n",
       "  'summary': 'Details single-pass online statistical algorithms which are critical for data engineers focusing on real-time data processing and analysis. The algorithms described offer efficient ways to manage and compute statistics from potentially large streams of data, directly aligning with trending techniques in data engineering.',\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': 'b4eb43dd17',\n",
       "  'summary': \"This fragment discusses distributed checkpointing in LLM training workflows, emphasizing its importance for infrastructure engineers. Checkpointing involves taking snapshots of system states, crucial for recovering from interruptions in large data pipelines typical in ML training. It details the mechanics of transferring data from VRAM to RAM, the high-level steps for checkpointing, and the significance of synchronization across nodes in distributed training environments, especially in the context of '3D parallelism'. The complexity of distributed checkpointing in scaling models poses challenges due to constraints from memory, network, and storage resources, marking it as a significant area of research and optimization in data engineering workflows.\",\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': '3614585ef1',\n",
       "  'summary': 'This fragment captures insights into the constraints of releasing AI models in a free software environment. It emphasizes the complexities and conditions surrounding AI training data and model releases, offering a broader perspective on data management ethics and standards in engineering, which are relevant to the field, particularly in AI-driven data engineering.',\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': '2a0ca503a5',\n",
       "  'summary': 'This fragment discusses a notification system for object storage in a tech environment, mentioning features like automatic image processing which can relate indirectly to data engineering through application workflows. However, its primary focus is not on data engineering specific techniques or methodologies, making it only loosely relevant.',\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': 'dacc6cbf50',\n",
       "  'summary': 'This fragment discusses testing tools for gRPC services, focusing on a Go-based tests-coverage-tool that measures automated testing coverage for gRPC methods. It highlights the importance of comprehensive testing for evolving services and introduces concepts such as Goroutines and Mutexes to prevent race conditions in Go applications, which are relevant for building scalable and efficient systems in data engineering.',\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': 'f56a209e2c',\n",
       "  'summary': 'This fragment describes frameworks for handling failures in systems, which is crucial for data engineering as it emphasizes recovery and resilience strategies in system design. Understanding failure mitigation is essential for robust data pipelines and infrastructure.',\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': '818ee3f8a6',\n",
       "  'summary': 'The fragment discusses the evolution of storage from 1987, highlighting the transition from floppy disks to internal hard disks in Macs, specifically how issues like fragmentation arise in data storage systems and the methodologies such as defragmentation that were historically employed to enhance performance. This relates indirectly to data engineering in terms of understanding data storage systems, maintenance, and the importance of optimizing data management for performance.',\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': 'e406a7ef42',\n",
       "  'summary': 'This fragment covers the implementation of SSHFP DNS records for secure verification of SSH host keys, emphasizing automation in security protocols. While primarily focused on network security, it demonstrates the necessity of robust data management practices—essential in data engineering contexts, particularly when dealing with accessible and secure database connections.',\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': 'e92a794d85',\n",
       "  'summary': 'Focusing on engineering headcount costs, this fragment discusses the implications of hiring policies on seniority mix and engineering costs in organizations. Understanding staffing and resource allocation can be beneficial for data engineering leaders to optimize team performance and costs associated with data engineering functions.',\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': 'cbcdb8b292',\n",
       "  'summary': 'The fragment introduces new template strings in Python, which allow for intercepting and transforming interpolated values. This improvement over f-strings enables more secure and flexible string handling - an essential concept in data engineering when constructing queries or processing data securely and efficiently.',\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': 'FRAGMENT_0b6da052f8',\n",
       "  'summary': 'The fragment discusses the lack of accessible price databases for services like barbers and CPAs, indicating a possible area of exploration for data engineering through the aggregation and management of service pricing data.',\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': 'FRAGMENT_713b924970',\n",
       "  'summary': 'The discussion revolves around improving user experience with command line tools by enhancing the readability of documentation. This highlights the importance of effective data presentation and user-interface design in data engineering processes.',\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': 'FRAGMENT_9237009917',\n",
       "  'summary': 'This fragment discusses building an AI-powered tool for standup meetings, which aligns closely with data engineering as it involves integrating data from various sources and creating a knowledge base for team updates.',\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': 'FRAGMENT_1739a8b952',\n",
       "  'summary': 'This fragment lists fundamental practices in software development, which are relevant to data engineering as they emphasize the importance of testing, documentation, and understanding problem-solving in software processes.',\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': 'FRAGMENT_bd90cbb552',\n",
       "  'summary': 'This segment discusses the ethical concerns surrounding data handling in the firearms industry, showcasing the crucial aspects of data privacy and ethics in data engineering, although it does not directly reference data engineering methodologies.',\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': 'b9d45828f1',\n",
       "  'summary': \"Stripe's acquisition of Bridge enhances its capabilities in stablecoin transactions, linking on-chain and off-chain systems. This move is significant for data engineering as it streamlines financial transactions by reducing intermediaries, suggesting a future where secure, faster B2B payments are processed through stablecoins. This could reshape data pipelines in finance, as businesses adapt to more efficient transaction models.\",\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': '0e9cfd38f3',\n",
       "  'summary': \"Jack Wrenn's talk on 'Safety Goggles for Alchemists' focuses on making type transmutation safer in Rust. Understanding safe data manipulation is critical for data engineers, enhancing memory safety and performance—areas where data engineering tools often struggle. This aligns with trends in programming languages emphasizing type safety and performance optimization.\",\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': '28d75f0ae5',\n",
       "  'summary': 'The discussion on OpenZFS deduplication highlights data management challenges, particularly concerning storage efficiency. This is relevant for data engineers, especially those involved in storage solutions, emphasizing the need for innovative approaches to tackling performance overheads in data systems.',\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': '35708e1d75',\n",
       "  'summary': 'This discusses breaches in corporate networks via VPN vulnerabilities, underscoring the importance of data security in engineering contexts. It emphasizes the need for robust data security measures in data engineering solutions, particularly with regard to sensitive financial data.',\n",
       "  'is_relevant': True},\n",
       " {'fragment_id': 'a2342caa7f',\n",
       "  'summary': 'This technical fragment outlines the principles of a new protocol combining features of existing internet protocols, focusing on efficient data transfer and error handling. Insights about networking and programming may apply loosely to data engineering, especially in data handling and efficient network communication.',\n",
       "  'is_relevant': True}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T12:04:48.358330Z",
     "start_time": "2024-10-29T12:04:48.349171Z"
    }
   },
   "cell_type": "code",
   "source": "len(extended_summary)",
   "id": "e6e8e650ed69e74c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T12:23:56.773136Z",
     "start_time": "2024-10-29T12:23:56.764931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# add original references to the data found\n",
    "def format_extended_summary(query: str, extended_summary: list[dict], original_data: list[dict]) -> str:\n",
    "    \"\"\"Pretty print the extended summary.\"\"\"\n",
    "    if not extended_summary:\n",
    "        out = f\"Query: **{query}**\\n\\nNo relevant data found.\"\n",
    "        return out\n",
    "    \n",
    "    out = f\"Query: **{query}**\\n\\nThe following posts found:\\n\\n\"\n",
    "    \n",
    "    urls = []\n",
    "    \n",
    "    for entry in extended_summary:\n",
    "        doc_uid = entry[\"fragment_id\"]\n",
    "        if doc_uid.startswith(\"FRAGMENT_\"):\n",
    "            doc_uid = doc_uid.removeprefix(\"FRAGMENT_\")\n",
    "        summary = entry[\"summary\"]\n",
    "        \n",
    "        # add from original data\n",
    "        for doc in original_data:\n",
    "            if doc[\"document_uid\"] == doc_uid:\n",
    "                ref = doc[\"url\"]\n",
    "                title = doc[\"title\"]\n",
    "                if ref not in urls:\n",
    "                    urls.append(ref)\n",
    "                    out += f\"[{title}]({ref})\\n\\n{summary}\\n\\n\"\n",
    "                \n",
    "                break\n",
    "\n",
    "    return out\n"
   ],
   "id": "eb671f19f645a960",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T12:24:04.918631Z",
     "start_time": "2024-10-29T12:24:04.903384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_stored(file_path: str) -> list:\n",
    "    stored = []\n",
    "    try:\n",
    "        with open(file_path, \"r\") as fp:\n",
    "            stored = json.load(fp)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        pass\n",
    "    \n",
    "    return stored\n",
    "\n",
    "stored_data = load_stored(hn_dump_file) + load_stored(lr_dump_file)"
   ],
   "id": "4bee3323a09efc93",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## The working example",
   "id": "339cb404d47396fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T12:31:28.925529Z",
     "start_time": "2024-10-29T12:31:28.910747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"physics challenges\"\n",
    "start_dt = datetime(2024, 10, 28, 0, 0)\n",
    "end_dt = datetime(2024, 11, 1, 0, 0)"
   ],
   "id": "9b9e2014bc69a84",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T12:32:30.767615Z",
     "start_time": "2024-10-29T12:31:32.023706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "out = format_extended_summary(\n",
    "    query,\n",
    "    rag_batched(query, build_summary_prompt, openai_llm_fn, milvus_search_fn, start_dt=start_dt, end_dt=end_dt),\n",
    "    stored_data\n",
    ")\n",
    "\n",
    "display(Markdown(out))"
   ],
   "id": "a2e5f148ecb6d276",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3b6eebd785f542c39fb9a4d86ae25ff1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Query: **physics challenges**\n\nThe following posts found:\n\n[Becoming physically immune to brute-force attacks](https://seirdy.one/posts/2021/01/12/password-strength/)\n\nThis fragment discusses the relationship between thermal physics, cosmology, and computer science in determining password strength against brute-force attacks. It introduces the concept of the 'Mother of All Computers' (MOAC), which serves as a theoretical limit for computational power based on mass-energy conservation. The discussion emphasizes the need for updated recommendations for password strength to resist future computational advances, particularly from supercomputers and quantum computers using Grover's algorithm.\n\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 61
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
